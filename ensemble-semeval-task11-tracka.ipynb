{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7e8f1cfbd3c34e6c9e3803248bd9434b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f6e508536604e5ca689345e47efee4a","IPY_MODEL_341f77e3bafc48308ece786bf7a4fff2","IPY_MODEL_aa753aa7b0f4472683f9bf48ad8a5d67"],"layout":"IPY_MODEL_f5c0e222800647189ae8696193762bed"}},"1f6e508536604e5ca689345e47efee4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3f151900d504b298964d25774e3f61d","placeholder":"​","style":"IPY_MODEL_4f59f1809ddb4ec49a5b80388dc1ecbb","value":"tokenizer_config.json: 100%"}},"341f77e3bafc48308ece786bf7a4fff2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7908c4ddfe51419e82484735328cf79f","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f645a301ff874324b620e541bf2e5b7e","value":48}},"aa753aa7b0f4472683f9bf48ad8a5d67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3f38a730c5c4296933d95afa5f0266c","placeholder":"​","style":"IPY_MODEL_a5613e83a94443aa98aef7da556cd002","value":" 48.0/48.0 [00:00&lt;00:00, 1.84kB/s]"}},"f5c0e222800647189ae8696193762bed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3f151900d504b298964d25774e3f61d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f59f1809ddb4ec49a5b80388dc1ecbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7908c4ddfe51419e82484735328cf79f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f645a301ff874324b620e541bf2e5b7e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b3f38a730c5c4296933d95afa5f0266c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5613e83a94443aa98aef7da556cd002":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87aa4c381fc0409b822412c42fa20a59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_334eb0996f7144229f187a7dde88d946","IPY_MODEL_7d37c869efcd4434bececb1688b3b4c4","IPY_MODEL_247a7f4858324515acd60a25362d16f5"],"layout":"IPY_MODEL_080bcd6babb244e4aa01b8771f291047"}},"334eb0996f7144229f187a7dde88d946":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04da5c70fc8546ec997293115c261793","placeholder":"​","style":"IPY_MODEL_7e9c8a65462c4bc099fed65b8921596e","value":"vocab.txt: 100%"}},"7d37c869efcd4434bececb1688b3b4c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24b18b63a74f4fa688dc04a93633a21d","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8c0c2b7ef5841da90577482409d4fda","value":231508}},"247a7f4858324515acd60a25362d16f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a6c5b174da0484ea3cf7744e6646368","placeholder":"​","style":"IPY_MODEL_cf7088c12d144cbbab138bbce1fb3181","value":" 232k/232k [00:00&lt;00:00, 2.31MB/s]"}},"080bcd6babb244e4aa01b8771f291047":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04da5c70fc8546ec997293115c261793":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e9c8a65462c4bc099fed65b8921596e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24b18b63a74f4fa688dc04a93633a21d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8c0c2b7ef5841da90577482409d4fda":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a6c5b174da0484ea3cf7744e6646368":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf7088c12d144cbbab138bbce1fb3181":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06eb04ad6cb44095b82b168e6942b65c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0805eb9d7b4d4c46b9203f13fe306c64","IPY_MODEL_88c22293c5fc4f1a86d2b88370afdcfb","IPY_MODEL_ed8ec0017fb44535a945e81fcbf3c928"],"layout":"IPY_MODEL_bdb8f29568864bc6b3825a3aaade5fdc"}},"0805eb9d7b4d4c46b9203f13fe306c64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aceb88bc0c8644078ac4c93709384a4a","placeholder":"​","style":"IPY_MODEL_234d667484294a7fbaab9217573fbc30","value":"tokenizer.json: 100%"}},"88c22293c5fc4f1a86d2b88370afdcfb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f42448481c346b88ca7359e11e608df","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4bc8d5714cbd4849b7bfd7d30b3cd650","value":466062}},"ed8ec0017fb44535a945e81fcbf3c928":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_912a74579a34460f8bce2b8cfe1d68c3","placeholder":"​","style":"IPY_MODEL_a83862fac54d4d0a8ce6372c55a6e82f","value":" 466k/466k [00:00&lt;00:00, 5.96MB/s]"}},"bdb8f29568864bc6b3825a3aaade5fdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aceb88bc0c8644078ac4c93709384a4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"234d667484294a7fbaab9217573fbc30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f42448481c346b88ca7359e11e608df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bc8d5714cbd4849b7bfd7d30b3cd650":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"912a74579a34460f8bce2b8cfe1d68c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a83862fac54d4d0a8ce6372c55a6e82f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49642a551a314d8c830dfcd46ed77044":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6f46f86d65b46d2aed28795e5a9249a","IPY_MODEL_c2a8741a08ea4f31939ab40116e5f298","IPY_MODEL_1e55d97a6aa94fb0be83b758ae514b7e"],"layout":"IPY_MODEL_31f68acb16714afd9ff66130d821227e"}},"a6f46f86d65b46d2aed28795e5a9249a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f82c4e759feb4b7290e125c93e8bd54d","placeholder":"​","style":"IPY_MODEL_ed204c58c71c4bf582fbff78c292e5d0","value":"config.json: 100%"}},"c2a8741a08ea4f31939ab40116e5f298":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bff4679a2f364536b8474b206043f2ae","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4ac4e6f8ccd49a08939464c01b67886","value":570}},"1e55d97a6aa94fb0be83b758ae514b7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07375bb341bc4fc6bcba09fb2d66791f","placeholder":"​","style":"IPY_MODEL_4d84b9dfbe0140f4a01f69fb8d089b59","value":" 570/570 [00:00&lt;00:00, 14.2kB/s]"}},"31f68acb16714afd9ff66130d821227e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f82c4e759feb4b7290e125c93e8bd54d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed204c58c71c4bf582fbff78c292e5d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bff4679a2f364536b8474b206043f2ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4ac4e6f8ccd49a08939464c01b67886":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07375bb341bc4fc6bcba09fb2d66791f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d84b9dfbe0140f4a01f69fb8d089b59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ede79ab6abe54d5494b85267d93628f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f168287b767428d9c9a6998645e0d21","IPY_MODEL_759a93d4110c45b8a3aaeef0f9bb67b0","IPY_MODEL_4a9788a94406429bba1f30a53a80191a"],"layout":"IPY_MODEL_4f0b535d41ee45cea714ab8454e0064d"}},"9f168287b767428d9c9a6998645e0d21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c995d465b3042398d097c43c553e866","placeholder":"​","style":"IPY_MODEL_0aab64ee263b4e42b4eb87d2075270b3","value":"model.safetensors: 100%"}},"759a93d4110c45b8a3aaeef0f9bb67b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f71b74dd856146fcb11dbd2230cd9693","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b663247a0ea476b895b2bbc51a5db4c","value":440449768}},"4a9788a94406429bba1f30a53a80191a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f50be7d1273f4e22ac9d4126ade676d9","placeholder":"​","style":"IPY_MODEL_f758345d93b946e0935ff63194924331","value":" 440M/440M [00:04&lt;00:00, 132MB/s]"}},"4f0b535d41ee45cea714ab8454e0064d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c995d465b3042398d097c43c553e866":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aab64ee263b4e42b4eb87d2075270b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f71b74dd856146fcb11dbd2230cd9693":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b663247a0ea476b895b2bbc51a5db4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f50be7d1273f4e22ac9d4126ade676d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f758345d93b946e0935ff63194924331":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10444470,"sourceType":"datasetVersion","datasetId":6464861},{"sourceId":10444502,"sourceType":"datasetVersion","datasetId":6464886},{"sourceId":10449398,"sourceType":"datasetVersion","datasetId":6468045},{"sourceId":10449849,"sourceType":"datasetVersion","datasetId":6468377},{"sourceId":10451561,"sourceType":"datasetVersion","datasetId":6469647},{"sourceId":10523560,"sourceType":"datasetVersion","datasetId":6513066},{"sourceId":10524681,"sourceType":"datasetVersion","datasetId":6513782},{"sourceId":10571682,"sourceType":"datasetVersion","datasetId":6541715},{"sourceId":10601887,"sourceType":"datasetVersion","datasetId":6562504},{"sourceId":10615570,"sourceType":"datasetVersion","datasetId":6572270},{"sourceId":10615821,"sourceType":"datasetVersion","datasetId":6572432},{"sourceId":10615891,"sourceType":"datasetVersion","datasetId":6572489},{"sourceId":10616016,"sourceType":"datasetVersion","datasetId":6572594},{"sourceId":10616237,"sourceType":"datasetVersion","datasetId":6572769},{"sourceId":10616455,"sourceType":"datasetVersion","datasetId":6572931},{"sourceId":10616624,"sourceType":"datasetVersion","datasetId":6573070},{"sourceId":10618086,"sourceType":"datasetVersion","datasetId":6574095}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score\nfrom transformers import Trainer, TrainingArguments\nimport accelerate\n\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score\nimport matplotlib.pyplot as plt\nimport re","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r1VEINuKo8ot","outputId":"d840e6f9-4275-44aa-c3d4-018df65c5bf6","trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:31:39.329645Z","iopub.execute_input":"2025-01-30T17:31:39.330004Z","iopub.status.idle":"2025-01-30T17:31:39.336088Z","shell.execute_reply.started":"2025-01-30T17:31:39.329972Z","shell.execute_reply":"2025-01-30T17:31:39.335039Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"!wget -P /kaggle/working -nc \"https://raw.githubusercontent.com/MuhammadAreebKazmi2/Deep-Learning/refs/heads/main/Project/Seamless%20Translation/Track%20A/ukr_a_translated.csv\"\n!wget -P /kaggle/working -nc \"https://raw.githubusercontent.com/HammadxSaj/SemEval_Task11_Dataset/refs/heads/main/test_eng.csv\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1A93YFr2q4HI","outputId":"a946b7f9-9d7b-440f-d3c5-d3bc05207b54","execution":{"iopub.status.busy":"2025-01-30T17:31:39.348510Z","iopub.execute_input":"2025-01-30T17:31:39.348766Z","iopub.status.idle":"2025-01-30T17:31:41.531208Z","shell.execute_reply.started":"2025-01-30T17:31:39.348741Z","shell.execute_reply":"2025-01-30T17:31:41.530321Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"File '/kaggle/working/ukr_a_translated.csv' already there; not retrieving.\n\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"File '/kaggle/working/test_eng.csv' already there; not retrieving.\n\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/ukr_a_translated.csv')\ndf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"WVdasCDoqdXX","outputId":"077fc09c-20a2-47cc-c533-274ad16860a0","execution":{"iopub.status.busy":"2025-01-30T17:31:41.533108Z","iopub.execute_input":"2025-01-30T17:31:41.533426Z","iopub.status.idle":"2025-01-30T17:31:41.557183Z","shell.execute_reply.started":"2025-01-30T17:31:41.533396Z","shell.execute_reply":"2025-01-30T17:31:41.556309Z"},"trusted":true},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"                           id  \\\n0     ukr_train_track_a_00001   \n1     ukr_train_track_a_00002   \n2     ukr_train_track_a_00003   \n3     ukr_train_track_a_00004   \n4     ukr_train_track_a_00005   \n...                       ...   \n2461  ukr_train_track_a_02462   \n2462  ukr_train_track_a_02463   \n2463  ukr_train_track_a_02464   \n2464  ukr_train_track_a_02465   \n2465  ukr_train_track_a_02466   \n\n                                                   text  anger  disgust  fear  \\\n0                    I want a guitar and record covers.      0        0     0   \n1     I'm not sure if I'm going to be able to get my...      0        0     0   \n2     I'd like a little snow for the holidays for th...      0        0     0   \n3     When I first met you, you had a long, long hai...      0        0     0   \n4          I'm so glad I didn't expect such a reaction.      0        0     0   \n...                                                 ...    ...      ...   ...   \n2461               I'm in my third day of the marathon.      0        0     0   \n2462  Dionysius could not refuse her request and wen...      0        0     0   \n2463  The Russian hair was photographed by a woman i...      0        0     0   \n2464             Evidence of a Broken Train in the Corn      0        0     0   \n2465           I won't be able to make it to the party.      0        0     0   \n\n      joy  sadness  surprise  \n0       0        0         0  \n1       1        0         0  \n2       0        0         0  \n3       0        0         0  \n4       1        0         1  \n...   ...      ...       ...  \n2461    0        0         0  \n2462    0        0         0  \n2463    0        0         0  \n2464    0        0         0  \n2465    0        1         0  \n\n[2466 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>anger</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ukr_train_track_a_00001</td>\n      <td>I want a guitar and record covers.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ukr_train_track_a_00002</td>\n      <td>I'm not sure if I'm going to be able to get my...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ukr_train_track_a_00003</td>\n      <td>I'd like a little snow for the holidays for th...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ukr_train_track_a_00004</td>\n      <td>When I first met you, you had a long, long hai...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ukr_train_track_a_00005</td>\n      <td>I'm so glad I didn't expect such a reaction.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2461</th>\n      <td>ukr_train_track_a_02462</td>\n      <td>I'm in my third day of the marathon.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2462</th>\n      <td>ukr_train_track_a_02463</td>\n      <td>Dionysius could not refuse her request and wen...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2463</th>\n      <td>ukr_train_track_a_02464</td>\n      <td>The Russian hair was photographed by a woman i...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2464</th>\n      <td>ukr_train_track_a_02465</td>\n      <td>Evidence of a Broken Train in the Corn</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2465</th>\n      <td>ukr_train_track_a_02466</td>\n      <td>I won't be able to make it to the party.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2466 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/remaining/ukr_translated.csv')\ndf_test","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"AzTt-wHO-gte","outputId":"06066f83-7fd8-4bc4-ab13-9179fff0919c","execution":{"iopub.status.busy":"2025-01-30T17:31:41.558286Z","iopub.execute_input":"2025-01-30T17:31:41.558530Z","iopub.status.idle":"2025-01-30T17:31:41.578206Z","shell.execute_reply.started":"2025-01-30T17:31:41.558506Z","shell.execute_reply":"2025-01-30T17:31:41.577412Z"},"trusted":true},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"                          id  \\\n0     ukr_test_track_a_00001   \n1     ukr_test_track_a_00002   \n2     ukr_test_track_a_00003   \n3     ukr_test_track_a_00004   \n4     ukr_test_track_a_00005   \n...                      ...   \n2229  ukr_test_track_a_02230   \n2230  ukr_test_track_a_02231   \n2231  ukr_test_track_a_02232   \n2232  ukr_test_track_a_02233   \n2233  ukr_test_track_a_02234   \n\n                                                   text  anger  disgust  fear  \\\n0     I'm going to Bunyuel. I'm alone, but I'm happy...    NaN      NaN   NaN   \n1     Wonderful, everyone is alive and well, celebra...    NaN      NaN   NaN   \n2     On the other hand, if I drew it, it would be m...    NaN      NaN   NaN   \n3     I want to take the girl to Samoriddh, but ther...    NaN      NaN   NaN   \n4          I'm afraid of his words and his predictions.    NaN      NaN   NaN   \n...                                                 ...    ...      ...   ...   \n2229    \"Who's eating in the 3rd car?\" crowd: \"Nobody!\"    NaN      NaN   NaN   \n2230                       Can I die without suffering?    NaN      NaN   NaN   \n2231                         And for now, sweet dreams.    NaN      NaN   NaN   \n2232  Today I accidentally read an article about Por...    NaN      NaN   NaN   \n2233  Wow, well, that kind of fatality has to end in...    NaN      NaN   NaN   \n\n      joy  sadness  surprise  \n0     NaN      NaN       NaN  \n1     NaN      NaN       NaN  \n2     NaN      NaN       NaN  \n3     NaN      NaN       NaN  \n4     NaN      NaN       NaN  \n...   ...      ...       ...  \n2229  NaN      NaN       NaN  \n2230  NaN      NaN       NaN  \n2231  NaN      NaN       NaN  \n2232  NaN      NaN       NaN  \n2233  NaN      NaN       NaN  \n\n[2234 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>anger</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ukr_test_track_a_00001</td>\n      <td>I'm going to Bunyuel. I'm alone, but I'm happy...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ukr_test_track_a_00002</td>\n      <td>Wonderful, everyone is alive and well, celebra...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ukr_test_track_a_00003</td>\n      <td>On the other hand, if I drew it, it would be m...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ukr_test_track_a_00004</td>\n      <td>I want to take the girl to Samoriddh, but ther...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ukr_test_track_a_00005</td>\n      <td>I'm afraid of his words and his predictions.</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2229</th>\n      <td>ukr_test_track_a_02230</td>\n      <td>\"Who's eating in the 3rd car?\" crowd: \"Nobody!\"</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2230</th>\n      <td>ukr_test_track_a_02231</td>\n      <td>Can I die without suffering?</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2231</th>\n      <td>ukr_test_track_a_02232</td>\n      <td>And for now, sweet dreams.</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2232</th>\n      <td>ukr_test_track_a_02233</td>\n      <td>Today I accidentally read an article about Por...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2233</th>\n      <td>ukr_test_track_a_02234</td>\n      <td>Wow, well, that kind of fatality has to end in...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2234 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport re\n\n# Step 2: Clean the text data\ndef clean_text(text):\n    # Remove HTML tags\n    text = BeautifulSoup(text, \"html.parser\").get_text()\n    # Remove numbers (but keep special characters)\n    text = re.sub(r'[^a-zA-Z\\s!\\'\"?,.;:]', '', text)\n    # Convert to lowercase\n    text = text.lower()\n    # Remove extra whitespace\n    text = ' '.join(text.split())\n    return text\n\n# Apply the clean_text function\ndf_test['text'] = df_test['text'].apply(clean_text)\n\n# Step 3-5: (Same as your original code)\ndf_test = df_test[df_test['text'].notna() & (df_test['text'] != '')]\n\n# Ensure emotion columns are integers\n# emotion_columns = ['Anger', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise']\nemotion_columns = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n# emotion_columns = ['anger', 'disgust', 'fear', 'joy', 'sadness']\ndf_test[emotion_columns] = df_test[emotion_columns]\n\n# Save the processed data back to CSV\noutput_path = '/kaggle/working/cleaned_test_english.csv'\ndf_test.to_csv(output_path, index=False)\n\nprint(f\"Data preprocessing completed. File 'cleaned_test_english.csv' has been created in the /kaggle/working directory.\")\n\n# Display statistics and processed examples\nprint(f\"Total samples: {len(df_test)}\")\nprint(\"\\nEmotion distribution in the dataset:\")\nprint(df_test[emotion_columns].sum())\nprint(\"\\nFirst few processed examples:\")\nprint(df_test.head())\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"joznalnz_Xq_","outputId":"ada4c0f0-ab58-4a52-8829-ffa2c8f86c27","execution":{"iopub.status.busy":"2025-01-30T17:31:41.579810Z","iopub.execute_input":"2025-01-30T17:31:41.580059Z","iopub.status.idle":"2025-01-30T17:31:41.694211Z","shell.execute_reply.started":"2025-01-30T17:31:41.580035Z","shell.execute_reply":"2025-01-30T17:31:41.693395Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Data preprocessing completed. File 'cleaned_test_english.csv' has been created in the /kaggle/working directory.\nTotal samples: 2234\n\nEmotion distribution in the dataset:\nanger       0.0\ndisgust     0.0\nfear        0.0\njoy         0.0\nsadness     0.0\nsurprise    0.0\ndtype: float64\n\nFirst few processed examples:\n                       id                                               text  \\\n0  ukr_test_track_a_00001  i'm going to bunyuel. i'm alone, but i'm happy...   \n1  ukr_test_track_a_00002  wonderful, everyone is alive and well, celebra...   \n2  ukr_test_track_a_00003  on the other hand, if i drew it, it would be m...   \n3  ukr_test_track_a_00004  i want to take the girl to samoriddh, but ther...   \n4  ukr_test_track_a_00005       i'm afraid of his words and his predictions.   \n\n   anger  disgust  fear  joy  sadness  surprise  \n0    NaN      NaN   NaN  NaN      NaN       NaN  \n1    NaN      NaN   NaN  NaN      NaN       NaN  \n2    NaN      NaN   NaN  NaN      NaN       NaN  \n3    NaN      NaN   NaN  NaN      NaN       NaN  \n4    NaN      NaN   NaN  NaN      NaN       NaN  \n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/3384993339.py:7: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  text = BeautifulSoup(text, \"html.parser\").get_text()\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"if 'id' in df.columns:\n    df = df.drop(['id'], axis=1)\nfrom bs4 import BeautifulSoup\nimport re\n\n# Step 2: Clean the text data\ndef clean_text(text):\n    # Remove HTML tags\n    text = BeautifulSoup(text, \"html.parser\").get_text()\n    # Remove numbers (but keep special characters)\n    text = re.sub(r'[^a-zA-Z\\s!\\'\"?,.;:]', '', text)\n    # Convert to lowercase\n    text = text.lower()\n    # Remove extra whitespace\n    text = ' '.join(text.split())\n    return text\n\n# df['text'] = df['text'].apply(clean_text)\n\n# Step 3: Remove rows with empty text\ndf = df[df['text'].notna() & (df['text'] != '')]\n\n# Step 4: Ensure emotion columns are integers\n#emotion_columns = ['Anger', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise']\nemotion_columns = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n# emotion_columns = ['anger', 'disgust', 'fear', 'joy', 'sadness']\ndf[emotion_columns] = df[emotion_columns].astype(int)\n\n# Step 5: Save the processed data back to CSV\noutput_path = '/kaggle/working/cleaned_train_english.csv'\ndf.to_csv(output_path, index=False)\n\nprint(f\"Data preprocessing completed. File 'cleaned_train_english.csv' has been created in the /kaggle/working directory.\")\n\n# Optional: Display some statistics about the data\nprint(f\"Total samples: {len(df)}\")\nprint(\"\\nEmotion distribution in the dataset:\")\nprint(df[emotion_columns].sum())\n\n# Optional: Display a few processed examples\nprint(\"\\nFirst few processed examples:\")\nprint(df.head())","metadata":{"id":"Avk15dNYrYQx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7f87d4c7-2a11-49e0-cdd7-1800b717892c","execution":{"iopub.status.busy":"2025-01-30T17:31:41.695092Z","iopub.execute_input":"2025-01-30T17:31:41.695353Z","iopub.status.idle":"2025-01-30T17:31:41.719405Z","shell.execute_reply.started":"2025-01-30T17:31:41.695329Z","shell.execute_reply":"2025-01-30T17:31:41.718595Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Data preprocessing completed. File 'cleaned_train_english.csv' has been created in the /kaggle/working directory.\nTotal samples: 2466\n\nEmotion distribution in the dataset:\nanger        98\ndisgust      86\nfear        172\njoy         412\nsadness     333\nsurprise    196\ndtype: int64\n\nFirst few processed examples:\n                                                text  anger  disgust  fear  \\\n0                 I want a guitar and record covers.      0        0     0   \n1  I'm not sure if I'm going to be able to get my...      0        0     0   \n2  I'd like a little snow for the holidays for th...      0        0     0   \n3  When I first met you, you had a long, long hai...      0        0     0   \n4       I'm so glad I didn't expect such a reaction.      0        0     0   \n\n   joy  sadness  surprise  \n0    0        0         0  \n1    1        0         0  \n2    0        0         0  \n3    0        0         0  \n4    1        0         1  \n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\ntokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=6, problem_type=\"multi_label_classification\")\n# model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=6, problem_type=\"multi_label_classification\")","metadata":{"id":"87WxmPMwzflF","colab":{"base_uri":"https://localhost:8080/","height":379,"referenced_widgets":["7e8f1cfbd3c34e6c9e3803248bd9434b","1f6e508536604e5ca689345e47efee4a","341f77e3bafc48308ece786bf7a4fff2","aa753aa7b0f4472683f9bf48ad8a5d67","f5c0e222800647189ae8696193762bed","f3f151900d504b298964d25774e3f61d","4f59f1809ddb4ec49a5b80388dc1ecbb","7908c4ddfe51419e82484735328cf79f","f645a301ff874324b620e541bf2e5b7e","b3f38a730c5c4296933d95afa5f0266c","a5613e83a94443aa98aef7da556cd002","87aa4c381fc0409b822412c42fa20a59","334eb0996f7144229f187a7dde88d946","7d37c869efcd4434bececb1688b3b4c4","247a7f4858324515acd60a25362d16f5","080bcd6babb244e4aa01b8771f291047","04da5c70fc8546ec997293115c261793","7e9c8a65462c4bc099fed65b8921596e","24b18b63a74f4fa688dc04a93633a21d","e8c0c2b7ef5841da90577482409d4fda","8a6c5b174da0484ea3cf7744e6646368","cf7088c12d144cbbab138bbce1fb3181","06eb04ad6cb44095b82b168e6942b65c","0805eb9d7b4d4c46b9203f13fe306c64","88c22293c5fc4f1a86d2b88370afdcfb","ed8ec0017fb44535a945e81fcbf3c928","bdb8f29568864bc6b3825a3aaade5fdc","aceb88bc0c8644078ac4c93709384a4a","234d667484294a7fbaab9217573fbc30","6f42448481c346b88ca7359e11e608df","4bc8d5714cbd4849b7bfd7d30b3cd650","912a74579a34460f8bce2b8cfe1d68c3","a83862fac54d4d0a8ce6372c55a6e82f","49642a551a314d8c830dfcd46ed77044","a6f46f86d65b46d2aed28795e5a9249a","c2a8741a08ea4f31939ab40116e5f298","1e55d97a6aa94fb0be83b758ae514b7e","31f68acb16714afd9ff66130d821227e","f82c4e759feb4b7290e125c93e8bd54d","ed204c58c71c4bf582fbff78c292e5d0","bff4679a2f364536b8474b206043f2ae","f4ac4e6f8ccd49a08939464c01b67886","07375bb341bc4fc6bcba09fb2d66791f","4d84b9dfbe0140f4a01f69fb8d089b59","ede79ab6abe54d5494b85267d93628f1","9f168287b767428d9c9a6998645e0d21","759a93d4110c45b8a3aaeef0f9bb67b0","4a9788a94406429bba1f30a53a80191a","4f0b535d41ee45cea714ab8454e0064d","0c995d465b3042398d097c43c553e866","0aab64ee263b4e42b4eb87d2075270b3","f71b74dd856146fcb11dbd2230cd9693","0b663247a0ea476b895b2bbc51a5db4c","f50be7d1273f4e22ac9d4126ade676d9","f758345d93b946e0935ff63194924331"]},"outputId":"85228e5c-c17d-4ba5-a043-e674630663d8","execution":{"iopub.status.busy":"2025-01-30T17:31:41.720602Z","iopub.execute_input":"2025-01-30T17:31:41.720843Z","iopub.status.idle":"2025-01-30T17:31:42.034624Z","shell.execute_reply.started":"2025-01-30T17:31:41.720820Z","shell.execute_reply":"2025-01-30T17:31:42.033980Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# Load tokenizer and model for sequence classification\ntokenizer_deberta = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\nmodel_deberta = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=6)  # Set num_labels according to your task","metadata":{"execution":{"iopub.status.busy":"2025-01-30T17:31:42.035536Z","iopub.execute_input":"2025-01-30T17:31:42.035762Z","iopub.status.idle":"2025-01-30T17:31:43.746089Z","shell.execute_reply.started":"2025-01-30T17:31:42.035739Z","shell.execute_reply":"2025-01-30T17:31:43.745383Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:558: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline\ntokenizer_xlm_roberta = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\nmodel_xlm_roberta = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=6)","metadata":{"execution":{"iopub.status.busy":"2025-01-30T17:31:43.747623Z","iopub.execute_input":"2025-01-30T17:31:43.747921Z","iopub.status.idle":"2025-01-30T17:31:45.779302Z","shell.execute_reply.started":"2025-01-30T17:31:43.747893Z","shell.execute_reply":"2025-01-30T17:31:45.778457Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"from datasets import load_dataset, Dataset, DatasetDict","metadata":{"id":"7x8yNyCmdUvL","execution":{"iopub.status.busy":"2025-01-30T17:31:45.780403Z","iopub.execute_input":"2025-01-30T17:31:45.780670Z","iopub.status.idle":"2025-01-30T17:31:45.784743Z","shell.execute_reply.started":"2025-01-30T17:31:45.780644Z","shell.execute_reply":"2025-01-30T17:31:45.783872Z"},"trusted":true},"outputs":[],"execution_count":59},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(df)\n\ntrain_dataset\n\ndataset = train_dataset.train_test_split(test_size=0.2)\ntrain_dataset = dataset['train']\nval_dataset = dataset['test']\nprint(dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8S-rgSc4d9_P","outputId":"63897843-5ba7-4ded-8e96-c185bf595c96","execution":{"iopub.status.busy":"2025-01-30T17:31:45.787532Z","iopub.execute_input":"2025-01-30T17:31:45.788090Z","iopub.status.idle":"2025-01-30T17:31:45.810178Z","shell.execute_reply.started":"2025-01-30T17:31:45.788062Z","shell.execute_reply":"2025-01-30T17:31:45.809370Z"},"trusted":true},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise'],\n        num_rows: 1972\n    })\n    test: Dataset({\n        features: ['text', 'anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise'],\n        num_rows: 494\n    })\n})\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"# Convert train_dataset and val_dataset back to Pandas DataFrame\ntrain_df = train_dataset.to_pandas()\nval_df = val_dataset.to_pandas()\n\n# Save to CSV\ntrain_df.to_csv('train_dataset.csv', index=False)\nval_df.to_csv('val_dataset.csv', index=False)\n\nprint(\"CSV files have been saved.\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDJWcCGL1tJQ","outputId":"9b8ddd1c-c5e6-4d0d-dcf5-e987c5fa1008","execution":{"iopub.status.busy":"2025-01-30T17:31:45.811202Z","iopub.execute_input":"2025-01-30T17:31:45.811518Z","iopub.status.idle":"2025-01-30T17:31:45.849336Z","shell.execute_reply.started":"2025-01-30T17:31:45.811482Z","shell.execute_reply":"2025-01-30T17:31:45.848523Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CSV files have been saved.\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"train_df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"NEyqsWS22IHY","outputId":"0ebeed91-1293-4427-e601-419344a103b6","execution":{"iopub.status.busy":"2025-01-30T17:31:45.850288Z","iopub.execute_input":"2025-01-30T17:31:45.850530Z","iopub.status.idle":"2025-01-30T17:31:45.859278Z","shell.execute_reply.started":"2025-01-30T17:31:45.850506Z","shell.execute_reply":"2025-01-30T17:31:45.858447Z"},"trusted":true},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"                                                text  anger  disgust  fear  \\\n0  Old man, all my life I've been afraid to look ...      0        0     1   \n1            It's like a cold wind blows through me.      0        0     0   \n2  I clarify that there were norms in that family...      0        0     0   \n3  I haven't dreamed of such horrors in a long ti...      0        0     1   \n4  If you're looking for a #VivaLIFE, don't miss ...      0        0     0   \n\n   joy  sadness  surprise  \n0    0        0         0  \n1    0        1         0  \n2    0        0         0  \n3    0        0         0  \n4    0        0         0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>anger</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Old man, all my life I've been afraid to look ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It's like a cold wind blows through me.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I clarify that there were norms in that family...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I haven't dreamed of such horrors in a long ti...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>If you're looking for a #VivaLIFE, don't miss ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"val_df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ku3zJJGE2V1f","outputId":"7bc897e7-658f-41e8-fef1-be0e1e06cdbb","execution":{"iopub.status.busy":"2025-01-30T17:31:45.860440Z","iopub.execute_input":"2025-01-30T17:31:45.860762Z","iopub.status.idle":"2025-01-30T17:31:45.871380Z","shell.execute_reply.started":"2025-01-30T17:31:45.860727Z","shell.execute_reply":"2025-01-30T17:31:45.870537Z"},"trusted":true},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"                                                text  anger  disgust  fear  \\\n0  And I had almost lost hope and had time to cry...      0        0     0   \n1  The Twitter-based social media platform, which...      0        0     0   \n2         \"Lunar\" is a euphemism for drug addiction.      0        0     0   \n3  You're still smoking on the move in this weather.      0        0     0   \n4                       Who said anything about you?      0        0     0   \n\n   joy  sadness  surprise  \n0    0        1         0  \n1    0        0         0  \n2    0        0         0  \n3    0        0         1  \n4    0        0         1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>anger</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>And I had almost lost hope and had time to cry...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Twitter-based social media platform, which...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"Lunar\" is a euphemism for drug addiction.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You're still smoking on the move in this weather.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Who said anything about you?</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"cols = train_df.columns[1:]\ncols","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GWqZ914a2ask","outputId":"766e2c98-94b5-44c3-fbbb-c3fae0fdd4ef","execution":{"iopub.status.busy":"2025-01-30T17:31:45.872550Z","iopub.execute_input":"2025-01-30T17:31:45.872800Z","iopub.status.idle":"2025-01-30T17:31:45.881788Z","shell.execute_reply.started":"2025-01-30T17:31:45.872777Z","shell.execute_reply":"2025-01-30T17:31:45.881135Z"},"trusted":true},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"Index(['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise'], dtype='object')"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"training_labels = train_df[cols]\ntraining_labels = training_labels.to_numpy()\ntraining_labels = training_labels.astype(np.float32)\n\ntrain_sentences = train_df.text.values.tolist()\n\nvalidation_labels = val_df[cols]\nvalidation_labels = validation_labels.to_numpy()\nvalidation_labels = validation_labels.astype(np.float32)\n\nvalidation_sentences = val_df.text.values.tolist()","metadata":{"id":"q_2WD__M1RQj","execution":{"iopub.status.busy":"2025-01-30T17:31:45.882771Z","iopub.execute_input":"2025-01-30T17:31:45.883026Z","iopub.status.idle":"2025-01-30T17:31:45.891211Z","shell.execute_reply.started":"2025-01-30T17:31:45.882994Z","shell.execute_reply":"2025-01-30T17:31:45.890392Z"},"trusted":true},"outputs":[],"execution_count":65},{"cell_type":"code","source":"train_encodings = tokenizer(train_sentences, padding=True, truncation=True, max_length=512)\nval_encodings = tokenizer(validation_sentences, padding=True, truncation=True, max_length=512)","metadata":{"id":"AXythUFT0fWg","execution":{"iopub.status.busy":"2025-01-30T17:31:45.892378Z","iopub.execute_input":"2025-01-30T17:31:45.892655Z","iopub.status.idle":"2025-01-30T17:31:46.071754Z","shell.execute_reply.started":"2025-01-30T17:31:45.892627Z","shell.execute_reply":"2025-01-30T17:31:46.071050Z"},"trusted":true},"outputs":[],"execution_count":66},{"cell_type":"code","source":"from datasets import Dataset\nimport torch\nimport numpy as np\n\ntrain_dataset_new = Dataset.from_dict({\n    'input_ids': train_encodings['input_ids'],\n    'attention_mask': train_encodings['attention_mask'],\n    'labels': training_labels\n})\n\nvalidation_dataset = Dataset.from_dict({\n    'input_ids': val_encodings['input_ids'],\n    'attention_mask': val_encodings['attention_mask'],\n    'labels': validation_labels\n})","metadata":{"id":"CFoDBKr76S95","execution":{"iopub.status.busy":"2025-01-30T17:31:46.072703Z","iopub.execute_input":"2025-01-30T17:31:46.072938Z","iopub.status.idle":"2025-01-30T17:31:46.259959Z","shell.execute_reply.started":"2025-01-30T17:31:46.072916Z","shell.execute_reply":"2025-01-30T17:31:46.259289Z"},"trusted":true},"outputs":[],"execution_count":67},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n\nepochs = 2\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps=0,\n                                            num_training_steps=len(df) * epochs)\n\ntraining_arguments = TrainingArguments(\n    output_dir=\"distilbert_base_model\",\n    num_train_epochs=8,  # Adjust the number of epochs as needed\n    per_device_train_batch_size=32,  # Adjust based on your GPU memory\n    per_device_eval_batch_size=32,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",  # Do not save after each epoch\n    logging_dir='./logs',\n    logging_steps=10,\n    warmup_steps=500,\n    weight_decay=0.01,\n    report_to=[],  # Disable W&B logging\n    remove_unused_columns=False,  # IMPORTANT: Prevents the Trainer from removing columns\n)","metadata":{"id":"8w-7NOYQYos8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"077e9d27-bcd6-49f1-aa45-1ada730b3d32","execution":{"iopub.status.busy":"2025-01-30T17:31:46.261135Z","iopub.execute_input":"2025-01-30T17:31:46.261464Z","iopub.status.idle":"2025-01-30T17:31:46.300166Z","shell.execute_reply.started":"2025-01-30T17:31:46.261426Z","shell.execute_reply":"2025-01-30T17:31:46.299368Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"#defining the metrics to be calculated during training\ndef multi_label_metrics(predictions, labels,):\n    sigmoid = torch.nn.Sigmoid()\n    predictions = sigmoid(torch.tensor(predictions))\n    y_predictions = np.zeros(predictions.shape)\n    y_true = labels\n    y_predictions[np.where(predictions >= 0.5)] = 1\n    accuracy = accuracy_score(y_true, y_predictions)\n    f1 = f1_score(y_true, y_predictions, average='micro')\n    auc = roc_auc_score(y_true, y_predictions, average='micro')\n\n    metrics = {\n        'accuracy': accuracy,\n        'f1': f1,\n        'auc': auc\n    }\n\n    return metrics\n\n#defining the function to compute the metrics for each batch of data\ndef compute_metrics(p):\n    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n    result = multi_label_metrics(preds, p.label_ids)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2025-01-30T17:31:46.301207Z","iopub.execute_input":"2025-01-30T17:31:46.301465Z","iopub.status.idle":"2025-01-30T17:31:46.307308Z","shell.execute_reply.started":"2025-01-30T17:31:46.301440Z","shell.execute_reply":"2025-01-30T17:31:46.306419Z"},"trusted":true},"outputs":[],"execution_count":69},{"cell_type":"code","source":"import wandb\n\n# Initialize wandb with mode disabled\nwandb.init(mode=\"disabled\")","metadata":{"execution":{"iopub.status.busy":"2025-01-30T17:31:46.308661Z","iopub.execute_input":"2025-01-30T17:31:46.308915Z","iopub.status.idle":"2025-01-30T17:31:46.335082Z","shell.execute_reply.started":"2025-01-30T17:31:46.308891Z","shell.execute_reply":"2025-01-30T17:31:46.334289Z"},"trusted":true},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7ba76abfa470>"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"train_encodings_roberta = tokenizer_xlm_roberta(train_sentences, padding=True, truncation=True, max_length=512)\nval_encodings_roberta = tokenizer_xlm_roberta(validation_sentences, padding=True, truncation=True, max_length=512)\n\ntrain_dataset_roberta = Dataset.from_dict({\n    'input_ids': train_encodings_roberta['input_ids'],\n    'attention_mask': train_encodings_roberta['attention_mask'],\n    'labels': training_labels\n})\n\nvalidation_dataset_roberta = Dataset.from_dict({\n    'input_ids': val_encodings_roberta['input_ids'],\n    'attention_mask': val_encodings_roberta['attention_mask'],\n    'labels': validation_labels\n})\n\n\noptimizer_roberta = AdamW(model_xlm_roberta.parameters(), lr=5e-5, eps=1e-8)\ntraining_arguments_roberta = TrainingArguments(\n    output_dir=\"roberta_base_model\",\n    num_train_epochs=8,  # Adjust the number of epochs as needed\n    per_device_train_batch_size=32,  # Adjust based on your GPU memory\n    per_device_eval_batch_size=32,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",  # Do not save after each epoch\n    logging_dir='./logs',\n    logging_steps=10,\n    warmup_steps=500,\n    weight_decay=0.01,\n    report_to=[],  # Disable W&B logging\n    remove_unused_columns=False,  # IMPORTANT: Prevents the Trainer from removing columns\n)\n\ntrainer_roberta = Trainer(\n    model=model_xlm_roberta,\n    args=training_arguments_roberta,\n    train_dataset=train_dataset_roberta,\n    eval_dataset=validation_dataset_roberta,\n    compute_metrics=compute_metrics\n)\n\ntrainer_roberta.train()","metadata":{"execution":{"iopub.status.busy":"2025-01-30T17:31:46.336095Z","iopub.execute_input":"2025-01-30T17:31:46.336371Z","iopub.status.idle":"2025-01-30T17:39:18.147818Z","shell.execute_reply.started":"2025-01-30T17:31:46.336347Z","shell.execute_reply":"2025-01-30T17:39:18.146988Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [248/248 07:29, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.679800</td>\n      <td>0.619239</td>\n      <td>0.251012</td>\n      <td>0.098361</td>\n      <td>0.490106</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.527600</td>\n      <td>0.451213</td>\n      <td>0.522267</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.356300</td>\n      <td>0.284660</td>\n      <td>0.522267</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.275900</td>\n      <td>0.271567</td>\n      <td>0.522267</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.279900</td>\n      <td>0.266212</td>\n      <td>0.522267</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.275500</td>\n      <td>0.250194</td>\n      <td>0.522267</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.244100</td>\n      <td>0.244030</td>\n      <td>0.556680</td>\n      <td>0.213333</td>\n      <td>0.560834</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.237900</td>\n      <td>0.237270</td>\n      <td>0.576923</td>\n      <td>0.298780</td>\n      <td>0.593083</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=248, training_loss=0.37833818024204624, metrics={'train_runtime': 450.6441, 'train_samples_per_second': 35.008, 'train_steps_per_second': 0.55, 'total_flos': 2091709343225088.0, 'train_loss': 0.37833818024204624, 'epoch': 8.0})"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"model_xlm_roberta.save_pretrained(\"/kaggle/working/roberta_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:39:18.149045Z","iopub.execute_input":"2025-01-30T17:39:18.149694Z","iopub.status.idle":"2025-01-30T17:39:21.994607Z","shell.execute_reply.started":"2025-01-30T17:39:18.149649Z","shell.execute_reply":"2025-01-30T17:39:21.993889Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"for device_id in range(torch.cuda.device_count()):\n    torch.cuda.set_device(device_id)\n    torch.cuda.empty_cache()\n    print(f\"Cache emptied for GPU {device_id}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:39:21.995764Z","iopub.execute_input":"2025-01-30T17:39:21.996006Z","iopub.status.idle":"2025-01-30T17:39:22.292486Z","shell.execute_reply.started":"2025-01-30T17:39:21.995983Z","shell.execute_reply":"2025-01-30T17:39:22.291514Z"}},"outputs":[{"name":"stdout","text":"Cache emptied for GPU 0\nCache emptied for GPU 1\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"del model_xlm_roberta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:39:22.293603Z","iopub.execute_input":"2025-01-30T17:39:22.293936Z","iopub.status.idle":"2025-01-30T17:39:22.301029Z","shell.execute_reply.started":"2025-01-30T17:39:22.293899Z","shell.execute_reply":"2025-01-30T17:39:22.300369Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"del train_encodings_roberta\ndel val_encodings_roberta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:39:22.302089Z","iopub.execute_input":"2025-01-30T17:39:22.302426Z","iopub.status.idle":"2025-01-30T17:39:22.337334Z","shell.execute_reply.started":"2025-01-30T17:39:22.302389Z","shell.execute_reply":"2025-01-30T17:39:22.336338Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"# # Tokenize training and validation data\n# train_encodings_deberta = tokenizer_deberta(train_sentences, padding=True, truncation=True, max_length=512)\n# val_encodings_deberta = tokenizer_deberta(validation_sentences, padding=True, truncation=True, max_length=512)\n\n# # Create datasets\n# train_dataset_deberta = Dataset.from_dict({\n#     'input_ids': train_encodings_deberta['input_ids'],\n#     'attention_mask': train_encodings_deberta['attention_mask'],\n#     'labels': training_labels\n# })\n\n# validation_dataset_deberta = Dataset.from_dict({\n#     'input_ids': val_encodings_deberta['input_ids'],\n#     'attention_mask': val_encodings_deberta['attention_mask'],\n#     'labels': validation_labels\n# })\n\n# # Define optimizer, scheduler, and training arguments\n# optimizer_deberta = AdamW(model_deberta.parameters(), lr=5e-5, eps=1e-8)\n# training_arguments_deberta = TrainingArguments(\n#     output_dir=\"deberta-base-model\",\n#     num_train_epochs=4,  # Adjust the number of epochs as needed\n#     per_device_train_batch_size=32,  # Adjust based on your GPU memory\n#     per_device_eval_batch_size=32,\n#     evaluation_strategy=\"epoch\",\n#     save_strategy=\"no\",  # Do not save after each epoch\n#     logging_dir='./logs',\n#     logging_steps=10,\n#     warmup_steps=500,\n#     weight_decay=0.01,\n#     report_to=[],  # Disable W&B logging\n#     remove_unused_columns=False,  # IMPORTANT: Prevents the Trainer from removing columns\n# )\n\n# # Define the trainer and train\n# trainer_deberta = Trainer(\n#     model=model_deberta,\n#     args=training_arguments_deberta,\n#     train_dataset=train_dataset_deberta,\n#     eval_dataset=validation_dataset_deberta,\n#     compute_metrics=compute_metrics\n# )\n\n# trainer_deberta.train()","metadata":{"execution":{"iopub.status.busy":"2025-01-30T17:39:22.338688Z","iopub.execute_input":"2025-01-30T17:39:22.338965Z","iopub.status.idle":"2025-01-30T17:39:22.346161Z","shell.execute_reply.started":"2025-01-30T17:39:22.338941Z","shell.execute_reply":"2025-01-30T17:39:22.345371Z"},"trusted":true},"outputs":[],"execution_count":76},{"cell_type":"code","source":"# model_deberta.save_pretrained(\"/kaggle/working/deberta_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:39:22.347153Z","iopub.execute_input":"2025-01-30T17:39:22.347422Z","iopub.status.idle":"2025-01-30T17:39:22.358290Z","shell.execute_reply.started":"2025-01-30T17:39:22.347384Z","shell.execute_reply":"2025-01-30T17:39:22.357561Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"for device_id in range(torch.cuda.device_count()):\n    torch.cuda.set_device(device_id)\n    torch.cuda.empty_cache()\n    print(f\"Cache emptied for GPU {device_id}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:39:22.362381Z","iopub.execute_input":"2025-01-30T17:39:22.362715Z","iopub.status.idle":"2025-01-30T17:39:22.368689Z","shell.execute_reply.started":"2025-01-30T17:39:22.362681Z","shell.execute_reply":"2025-01-30T17:39:22.367923Z"}},"outputs":[{"name":"stdout","text":"Cache emptied for GPU 0\nCache emptied for GPU 1\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"# del model_deberta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:39:22.369551Z","iopub.execute_input":"2025-01-30T17:39:22.369792Z","iopub.status.idle":"2025-01-30T17:39:22.376662Z","shell.execute_reply.started":"2025-01-30T17:39:22.369769Z","shell.execute_reply":"2025-01-30T17:39:22.375808Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"# del train_encodings_deberta\n# del val_encodings_deberta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:39:22.377517Z","iopub.execute_input":"2025-01-30T17:39:22.377780Z","iopub.status.idle":"2025-01-30T17:39:22.384811Z","shell.execute_reply.started":"2025-01-30T17:39:22.377756Z","shell.execute_reply":"2025-01-30T17:39:22.383981Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"#defining the trainer\ntrainer = Trainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=train_dataset_new,\n    eval_dataset=validation_dataset,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"xq0ScxznCxMh","outputId":"df9566ce-e33d-4d8f-ef4a-e42c06fbc34f","execution":{"iopub.status.busy":"2025-01-30T17:39:22.385851Z","iopub.execute_input":"2025-01-30T17:39:22.386138Z","iopub.status.idle":"2025-01-30T17:43:43.852657Z","shell.execute_reply.started":"2025-01-30T17:39:22.386090Z","shell.execute_reply":"2025-01-30T17:43:43.851904Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [248/248 04:19, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.659900</td>\n      <td>0.650212</td>\n      <td>0.214575</td>\n      <td>0.054146</td>\n      <td>0.472059</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.579100</td>\n      <td>0.507461</td>\n      <td>0.522267</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.370300</td>\n      <td>0.329373</td>\n      <td>0.522267</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.291800</td>\n      <td>0.284831</td>\n      <td>0.522267</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.284900</td>\n      <td>0.273158</td>\n      <td>0.522267</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.281400</td>\n      <td>0.264642</td>\n      <td>0.522267</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.257500</td>\n      <td>0.247013</td>\n      <td>0.558704</td>\n      <td>0.180556</td>\n      <td>0.549842</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.232600</td>\n      <td>0.222291</td>\n      <td>0.595142</td>\n      <td>0.313480</td>\n      <td>0.596940</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=248, training_loss=0.38421200888772167, metrics={'train_runtime': 260.9995, 'train_samples_per_second': 60.445, 'train_steps_per_second': 0.95, 'total_flos': 1387860580200960.0, 'train_loss': 0.38421200888772167, 'epoch': 8.0})"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/distilbert_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:43:43.853902Z","iopub.execute_input":"2025-01-30T17:43:43.854284Z","iopub.status.idle":"2025-01-30T17:43:44.488309Z","shell.execute_reply.started":"2025-01-30T17:43:43.854244Z","shell.execute_reply":"2025-01-30T17:43:44.486917Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"del model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:43:44.489993Z","iopub.execute_input":"2025-01-30T17:43:44.490494Z","iopub.status.idle":"2025-01-30T17:43:44.495583Z","shell.execute_reply.started":"2025-01-30T17:43:44.490439Z","shell.execute_reply":"2025-01-30T17:43:44.494593Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"del train_encodings\ndel val_encodings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:43:44.496860Z","iopub.execute_input":"2025-01-30T17:43:44.497203Z","iopub.status.idle":"2025-01-30T17:43:44.544428Z","shell.execute_reply.started":"2025-01-30T17:43:44.497164Z","shell.execute_reply":"2025-01-30T17:43:44.543641Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"del trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:43:44.545709Z","iopub.execute_input":"2025-01-30T17:43:44.545985Z","iopub.status.idle":"2025-01-30T17:43:44.553419Z","shell.execute_reply.started":"2025-01-30T17:43:44.545960Z","shell.execute_reply":"2025-01-30T17:43:44.552597Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"# del trainer_deberta","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PGjBQqu1woZB","outputId":"9f048867-d764-4ac8-da0c-efad05e640b9","execution":{"iopub.status.busy":"2025-01-30T17:43:44.554859Z","iopub.execute_input":"2025-01-30T17:43:44.555223Z","iopub.status.idle":"2025-01-30T17:43:44.561284Z","shell.execute_reply.started":"2025-01-30T17:43:44.555186Z","shell.execute_reply":"2025-01-30T17:43:44.560426Z"},"trusted":true},"outputs":[],"execution_count":86},{"cell_type":"code","source":"del trainer_roberta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:43:44.562422Z","iopub.execute_input":"2025-01-30T17:43:44.562755Z","iopub.status.idle":"2025-01-30T17:43:44.571214Z","shell.execute_reply.started":"2025-01-30T17:43:44.562719Z","shell.execute_reply":"2025-01-30T17:43:44.570486Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"from transformers import DistilBertForSequenceClassification, DebertaV2ForSequenceClassification, XLMRobertaForSequenceClassification\n\n# Load BERT model\nmodel_bert = DistilBertForSequenceClassification.from_pretrained(\"/kaggle/working/distilbert_model/\")\n\n# Load DeBERTa model\n# model_deberta = DebertaV2ForSequenceClassification.from_pretrained(\"/kaggle/working/deberta_model/\")\n\nmodel_xlm_roberta = XLMRobertaForSequenceClassification.from_pretrained(\"/kaggle/working/roberta_model/\")\n\n# Set models to eval mode\nmodel_bert.eval()\n# model_deberta.eval()\nmodel_xlm_roberta.eval()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPdhLSuD6lpU","outputId":"73c19066-8728-431b-9e52-e81a3e0537f2","execution":{"iopub.status.busy":"2025-01-30T17:43:44.572559Z","iopub.execute_input":"2025-01-30T17:43:44.572849Z","iopub.status.idle":"2025-01-30T17:43:44.660623Z","shell.execute_reply.started":"2025-01-30T17:43:44.572816Z","shell.execute_reply":"2025-01-30T17:43:44.659926Z"},"trusted":true},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"XLMRobertaForSequenceClassification(\n  (roberta): XLMRobertaModel(\n    (embeddings): XLMRobertaEmbeddings(\n      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): XLMRobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x XLMRobertaLayer(\n          (attention): XLMRobertaAttention(\n            (self): XLMRobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): XLMRobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): XLMRobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): XLMRobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): XLMRobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"# Test data (assuming you have a DataFrame with a column 'text')\ntest_sentences = df_test['text'].tolist()\n\n# Tokenize the test data\ntest_encodings = tokenizer(test_sentences, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\ntest_encodings_deberta = tokenizer_deberta(test_sentences, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\ntest_encodings_roberta = tokenizer_xlm_roberta(test_sentences, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")","metadata":{"id":"wMj84RrN_DkR","execution":{"iopub.status.busy":"2025-01-30T17:43:44.661583Z","iopub.execute_input":"2025-01-30T17:43:44.661947Z","iopub.status.idle":"2025-01-30T17:43:45.441866Z","shell.execute_reply.started":"2025-01-30T17:43:44.661876Z","shell.execute_reply":"2025-01-30T17:43:45.441178Z"},"trusted":true},"outputs":[],"execution_count":89},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\n\n# Define a batch size\nbatch_size = 32  # Adjust based on your GPU memory\n\n# Create DataLoader for test data\ntest_dataset = TensorDataset(\n    test_encodings['input_ids'],\n    test_encodings['attention_mask'],\n    # test_encodings_deberta['input_ids'],\n    # test_encodings_deberta['attention_mask'],\n    test_encodings_roberta['input_ids'],\n    test_encodings_roberta['attention_mask']\n)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# Move models to the same device\ndevice = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\nmodel_bert.to(device)\n# model_deberta.to(device)\nmodel_xlm_roberta.to(device)\n\n# Initialize empty lists to store predictions\nall_probabilities_bert = []\n# all_probabilities_deberta = []\nall_probabilities_roberta = []\n\n# Process test data in batches\nsigmoid = torch.nn.Sigmoid()\n\nfor batch in test_loader:\n    # Unpack the batch\n    input_ids_bert, attention_mask_bert, input_ids_roberta, attention_mask_roberta = [\n        tensor.to(device) for tensor in batch\n    ]\n\n    # BERT Predictions\n    with torch.no_grad():\n        outputs_bert = model_bert(input_ids_bert, attention_mask=attention_mask_bert)\n        probabilities_bert = sigmoid(outputs_bert.logits)\n        all_probabilities_bert.append(probabilities_bert.cpu())\n\n    # DeBERTa Predictions\n    # with torch.no_grad():\n    #     outputs_deberta = model_deberta(input_ids_deberta, attention_mask=attention_mask_deberta)\n    #     probabilities_deberta = sigmoid(outputs_deberta.logits)\n    #     all_probabilities_deberta.append(probabilities_deberta.cpu())\n\n    # RoBERTa Predictions\n    with torch.no_grad():\n        outputs_roberta = model_xlm_roberta(input_ids_roberta, attention_mask=attention_mask_roberta)\n        probabilities_roberta = sigmoid(outputs_roberta.logits)\n        all_probabilities_roberta.append(probabilities_roberta.cpu())\n\n    # Clear GPU memory\n    for device_id in range(torch.cuda.device_count()):\n        torch.cuda.set_device(device_id)\n        torch.cuda.empty_cache()\n\n# Concatenate all batch predictions\nall_probabilities_bert = torch.cat(all_probabilities_bert, dim=0)\n# all_probabilities_deberta = torch.cat(all_probabilities_deberta, dim=0)\nall_probabilities_roberta = torch.cat(all_probabilities_roberta, dim=0)\n\n# Models can now be deleted if further processing is not needed\ndel model_bert, model_xlm_roberta\n\n# Final clearing of GPU memory\nfor device_id in range(torch.cuda.device_count()):\n    torch.cuda.set_device(device_id)\n    torch.cuda.empty_cache()\n\n# Output the predictions as numpy arrays\nprobabilities_bert_np = all_probabilities_bert.numpy()\n# probabilities_deberta_np = all_probabilities_deberta.numpy()\nprobabilities_roberta_np = all_probabilities_roberta.numpy()\n\nprint(\"Inference completed successfully.\")\n","metadata":{"id":"x-W8j8PJ_MyP","execution":{"iopub.status.busy":"2025-01-30T17:43:45.443046Z","iopub.execute_input":"2025-01-30T17:43:45.443320Z","iopub.status.idle":"2025-01-30T17:44:16.327498Z","shell.execute_reply.started":"2025-01-30T17:43:45.443296Z","shell.execute_reply":"2025-01-30T17:44:16.326613Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Inference completed successfully.\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"# Collect the probabilities in a list\nmodel_probabilities = [all_probabilities_bert, all_probabilities_roberta]\n\n# Function to compute averaged probabilities\ndef average_probabilities(probabilities_list, selected_models):\n    \"\"\"\n    Averages probabilities from selected models.\n\n    Args:\n    - probabilities_list: List of tensors containing probabilities from models.\n    - selected_models: List of indices of models to include in the average (e.g., [0, 1] for BERT and DeBERTa).\n\n    Returns:\n    - Averaged probabilities tensor.\n    \"\"\"\n    selected_probs = [probabilities_list[i] for i in selected_models]\n    return torch.stack(selected_probs).mean(dim=0)\n\n# Example Usage:\n# Average all three models (BERT, DeBERTa, RoBERTa)\naveraged_probabilities = average_probabilities(model_probabilities, selected_models=[0, 1])\n\n# Alternative averages (uncomment as needed):\n# averaged_probabilities = average_probabilities(model_probabilities, selected_models=[0, 1])  # BERT + DeBERTa\n# averaged_probabilities = average_probabilities(model_probabilities, selected_models=[0, 2])  # BERT + RoBERTa\n# averaged_probabilities = average_probabilities(model_probabilities, selected_models=[1, 2])  # DeBERTa + RoBERTa\n# averaged_probabilities = model_probabilities[2]  # Use RoBERTa only\n\n# Convert to binary predictions with a threshold\nthreshold = 0.4  # Adjust as needed\nfinal_predictions = (averaged_probabilities > threshold).int()\n\n# Print the shape and a few samples of the predictions\nprint(\"Final predictions shape:\", final_predictions.shape)\nprint(\"Sample predictions:\", final_predictions[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:44:16.328987Z","iopub.execute_input":"2025-01-30T17:44:16.329277Z","iopub.status.idle":"2025-01-30T17:44:16.338066Z","shell.execute_reply.started":"2025-01-30T17:44:16.329249Z","shell.execute_reply":"2025-01-30T17:44:16.337127Z"}},"outputs":[{"name":"stdout","text":"Final predictions shape: torch.Size([2234, 6])\nSample predictions: tensor([[0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 1, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 1, 0, 0, 0],\n        [0, 0, 1, 0, 0, 0]], dtype=torch.int32)\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"# Convert to a DataFrame\nlabel_columns = ['Anger', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise']\n# label_columns = ['Anger', 'Disgust', 'Fear', 'Joy', 'Sadness']\npredicted_df_ensemble = pd.DataFrame(final_predictions.cpu().numpy(), columns=label_columns)\n\n# Combine with the original test sentences\n\npredicted_df_ensemble = predicted_df_ensemble.round().astype(int)\n\nresult_df_ensemble = pd.concat([df_test['text'], predicted_df_ensemble], axis=1)\n\n# Display the results\nprint(result_df_ensemble.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:44:16.339104Z","iopub.execute_input":"2025-01-30T17:44:16.339400Z","iopub.status.idle":"2025-01-30T17:44:16.351783Z","shell.execute_reply.started":"2025-01-30T17:44:16.339376Z","shell.execute_reply":"2025-01-30T17:44:16.350967Z"}},"outputs":[{"name":"stdout","text":"                                                text  Anger  Disgust  Fear  \\\n0  i'm going to bunyuel. i'm alone, but i'm happy...      0        0     0   \n1  wonderful, everyone is alive and well, celebra...      0        0     0   \n2  on the other hand, if i drew it, it would be m...      0        0     0   \n3  i want to take the girl to samoriddh, but ther...      0        0     1   \n4       i'm afraid of his words and his predictions.      0        0     1   \n\n   Joy  Sadness  Surprise  \n0    0        0         0  \n1    1        0         0  \n2    0        0         0  \n3    0        0         0  \n4    0        0         0  \n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"result_df_ensemble['id'] = [f\"ukr_test_track_a_{str(i+1).zfill(5)}\" for i in range(len(result_df_ensemble))]\n\n# Step 4: Drop the original 'text' column\nresult_df_ensemble = result_df_ensemble.drop(columns=['text'])\n\n# Step 5: Reorder the columns so 'id' comes first, followed by the emotion labels\n# result_df_ensemble = result_df_ensemble[['id', 'Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']]\nresult_df_ensemble = result_df_ensemble[['id','Anger', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise']]\n# result_df_ensemble = result_df_ensemble[['id', 'Anger', 'Disgust', 'Fear', 'Joy', 'Sadness']]\n\n\n# Step 6: Save the final DataFrame as 'final_submission.csv' for submission\nresult_df_ensemble.to_csv('final_submission.csv', index=False)\n\n# Display the first few rows of the final DataFrame\nprint(result_df_ensemble.head())\n\nprint(\"Submission file 'final_submission.csv' has been created.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KFnLWDh_Ppe","outputId":"5527c1ce-ecd8-41aa-f150-20ad0c4c7410","execution":{"iopub.status.busy":"2025-01-30T17:44:16.352683Z","iopub.execute_input":"2025-01-30T17:44:16.352972Z","iopub.status.idle":"2025-01-30T17:44:16.375167Z","shell.execute_reply.started":"2025-01-30T17:44:16.352946Z","shell.execute_reply":"2025-01-30T17:44:16.374458Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                       id  Anger  Disgust  Fear  Joy  Sadness  Surprise\n0  ukr_test_track_a_00001      0        0     0    0        0         0\n1  ukr_test_track_a_00002      0        0     0    1        0         0\n2  ukr_test_track_a_00003      0        0     0    0        0         0\n3  ukr_test_track_a_00004      0        0     1    0        0         0\n4  ukr_test_track_a_00005      0        0     1    0        0         0\nSubmission file 'final_submission.csv' has been created.\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}